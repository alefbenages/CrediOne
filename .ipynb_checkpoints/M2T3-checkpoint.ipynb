{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# estimators\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#model metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Hyper parameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>Y_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID  LIMIT_BAL  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  \\\n",
       "0           1   1    20000.0    2.0    2.0   -1.0   -1.0   -2.0   -2.0   \n",
       "1           2   2   120000.0   -1.0    2.0    0.0    0.0    0.0    2.0   \n",
       "2           3   3    90000.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3           4   4    50000.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4           5   5    50000.0   -1.0    0.0   -1.0    0.0    0.0    0.0   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  Y_default  \n",
       "0       0.0     689.0       0.0       0.0          1  \n",
       "1       0.0    1000.0    1000.0    1000.0          1  \n",
       "2    1518.0    1500.0    1000.0    1000.0          0  \n",
       "3    2000.0    2019.0    1200.0    1100.0          0  \n",
       "4    2000.0   36681.0   10000.0    9000.0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import claned and pre-procesed data\n",
    "df = pd.read_csv('DF_M2T2_Light.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the features and Dependent Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Y_default']]\n",
    "X = df.drop('Y_default', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0 >> Divide data into: Train - Validation - Test\n",
    "\n",
    "Split data into: train, validation and test sets, or just train and test (depending on the function you will use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF:  (30000, 14)\n",
      "X:       (30000, 13) y:       (30000, 1)\n",
      "X_Train: (22500, 13) y_Train: (22500, 1)\n",
      "X_Valid: (4500, 13)  y_Valid: (4500, 1)\n",
      "X_Test:  (3000, 13)  y_Test:  (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now <train_ratio> % of the entire data set the _junk suffix means that we drop that variable completely\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1-train_ratio) )\n",
    "\n",
    "# test is now <test_ratio> % of the initial data set\n",
    "# validation is now <validation_ratio> % of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "print('DF: ', df.shape)\n",
    "print('X:      ', X.shape, 'y:      ', y.shape)\n",
    "print('X_Train:', X_train.shape,'y_Train:', y_train.shape)\n",
    "print('X_Valid:', X_val.shape, ' y_Valid:', y_val.shape)\n",
    "print('X_Test: ', X_test.shape,' y_Test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1\n",
    "\n",
    "Train the model on the training set and get the first performance measures on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of possible candidates\n",
    "algo_Candidates = []\n",
    "\n",
    "algo_Candidates.append(('Random Forest Regressor', RandomForestRegressor()))\n",
    "algo_Candidates.append(('Linear Regression', LinearRegression()))\n",
    "algo_Candidates.append(('Suport Vector Regression', SVR()))\n",
    "algo_Candidates.append(('Logistic Regression', LogisticRegression()))\n",
    "algo_Candidates.append(('k-NN', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:  Random Forest Regressor\n",
      "R Squared: 0.165\n",
      "RMSE: 0.377\n",
      "--------------------------------\n",
      "MODEL:  Linear Regression\n",
      "R Squared: 0.088\n",
      "RMSE: 0.394\n",
      "--------------------------------\n",
      "MODEL:  Suport Vector Regression\n",
      "R Squared: -0.082\n",
      "RMSE: 0.429\n",
      "--------------------------------\n",
      "MODEL:  Logistic Regression\n",
      "R Squared: -0.279\n",
      "RMSE: 0.467\n",
      "--------------------------------\n",
      "MODEL:  k-NN\n",
      "R Squared: -0.448\n",
      "RMSE: 0.497\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "performance=[]\n",
    "\n",
    "for name, model in algo_Candidates:\n",
    "    # train the model\n",
    "    model = model.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    # Get predictions and performance\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Measure\n",
    "    predictions = model.predict(X_val)\n",
    "    predRsquared = r2_score(y_val,predictions)\n",
    "    rmse = sqrt(mean_squared_error(y_val, predictions))\n",
    "    \n",
    "    # print results\n",
    "    print('MODEL: ',name)\n",
    "    print('R Squared: %.3f' % predRsquared)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # save the models into a list of tuples\n",
    "    models.append((name,model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: \n",
    "\n",
    "Train with Cross-Validation and select the best candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ale/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    result = cross_val_score(model, X_train, y_train.values.ravel(), cv=4, scoring='r2')\n",
    "    names.append(name)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.14827221, 0.17255285, 0.18456692, 0.13493525]),\n",
       " array([0.11333326, 0.12561562, 0.1277693 , 0.10612728]),\n",
       " array([-0.0713948 , -0.09241732, -0.09694658, -0.08520663]),\n",
       " array([-0.2851268 , -0.28542048, -0.28542048, -0.17015459]),\n",
       " array([-0.42517267, -0.46140679, -0.46140679, -0.43876527])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the best candidates\n",
    "\n",
    "As we used **r2** as scoring in the Cross-Val, we want to use the algorithms with values as close as possible to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor  r2 ->  0.16\n",
      "Linear Regression  r2 ->  0.12\n",
      "Suport Vector Regression  r2 ->  -0.09\n",
      "Logistic Regression  r2 ->  -0.26\n",
      "k-NN  r2 ->  -0.45\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(names)):\n",
    "    \n",
    "    print(names[i], ' r2 -> ', round(results[i].mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best algorithm is **Random Forest Regressor**. \n",
    "\n",
    "The negative value of **SVR** means that this model is not performing better than the most stupid one that's an horizontal line simple line, wich predicts always the same value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3:\n",
    "\n",
    "Find a better hyper-parameters values combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "# print the full list of parametrizable parameters\n",
    "model.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using RandomizedSearchCV\n",
    "\n",
    "GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use RandomizedSearchCV, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the parameters and distributions to sample from: param_dist\n",
    "\n",
    "# numers of trees\n",
    "n_estimators = [2,5,8,10]\n",
    "# max number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# max number of levels in tree\n",
    "max_depth = [5, 10, 15, 20]# 30, 40, 50]\n",
    "max_depth.append(None)\n",
    "# min number of samples required to split a node\n",
    "min_samples_split = [2,5,10,20,30]\n",
    "# min number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,5,10,15]\n",
    "\n",
    "\n",
    "param_dist = {#'bootstrap': True, \n",
    "              #'ccp_alpha': 0.0,\n",
    "              #'criterion': 'mse',\n",
    "              'n_estimators': n_estimators, \n",
    "              'max_features': max_features,\n",
    "              'max_depth':max_depth,\n",
    "              'min_samples_split':min_samples_split,\n",
    "              'min_samples_leaf':min_samples_leaf\n",
    "              #'max_leaf_nodes': None,\n",
    "              #'max_samples': None,\n",
    "              #'min_impurity_decrease': 0.0, \n",
    "              #'min_impurity_split': None, \n",
    "              #'min_weight_fraction_leaf': 0.0,           \n",
    "              #'n_jobs': None, \n",
    "              #'oob_score': False, \n",
    "              #'random_state': None,\n",
    "              #'verbose': 0, \n",
    "              #'warm_start': False\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the RandomizedSearchCV object: model_cv\n",
    "model_CV1 = RandomizedSearchCV(model, param_dist, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestRegressor(),\n",
       "                   param_distributions={'max_depth': [5, 10, 15, None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10, 15],\n",
       "                                        'min_samples_split': [2, 5, 10, 20, 30],\n",
       "                                        'n_estimators': [2, 5, 8, 10]})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the data\n",
    "model_CV1.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(model_CV1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18033566243654917\n"
     ]
    }
   ],
   "source": [
    "result_CV1 = cross_val_score(model_CV1, X_val, y_val.values.ravel(), cv=4, scoring='r2')\n",
    "print(result.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
